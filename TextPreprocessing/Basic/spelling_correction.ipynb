{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce2af96a",
   "metadata": {},
   "source": [
    "### 1. Using TextBlob (your version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12ec65e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a26110c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_text = \"Ths is a smple txt with som speling erors.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b021acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The is a smile txt with so spelling errors.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textBlb = TextBlob(incorrect_text)\n",
    "textBlb.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e14e6ab",
   "metadata": {},
   "source": [
    "### 2. Using autocorrect library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "550d3b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autocorrect\n",
      "  Using cached autocorrect-2.6.1.tar.gz (622 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [1 lines of output]\n",
      "      ERROR: Can not execute `setup.py` since setuptools is not available in the build environment.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cee5c6e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autocorrect'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mautocorrect\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Speller\n\u001b[0;32m      3\u001b[0m spell \u001b[38;5;241m=\u001b[39m Speller(lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m incorrect_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThs is a smple txt with som speling erors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'autocorrect'"
     ]
    }
   ],
   "source": [
    "from autocorrect import Speller\n",
    "\n",
    "spell = Speller(lang='en')\n",
    "incorrect_text = \"Ths is a smple txt with som speling erors.\"\n",
    "corrected_text = spell(incorrect_text)\n",
    "print(corrected_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884cda88",
   "metadata": {},
   "source": [
    "### 3. Using pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a93abcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spellchecker'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspellchecker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SpellChecker\n\u001b[0;32m      3\u001b[0m spell \u001b[38;5;241m=\u001b[39m SpellChecker()\n\u001b[0;32m      4\u001b[0m incorrect_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThs is a smple txt with som speling erors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spellchecker'"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "incorrect_text = \"Ths is a smple txt with som speling erors.\"\n",
    "corrected_words = [spell.correction(word) for word in incorrect_text.split()]\n",
    "corrected_text = \" \".join(corrected_words)\n",
    "print(corrected_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3108d0",
   "metadata": {},
   "source": [
    "### 4. Using gingerit (Ginger API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1cc0f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gingerit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgingerit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgingerit\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GingerIt\n\u001b[0;32m      3\u001b[0m parser \u001b[38;5;241m=\u001b[39m GingerIt()\n\u001b[0;32m      4\u001b[0m incorrect_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThs is a smple txt with som speling erors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gingerit'"
     ]
    }
   ],
   "source": [
    "from gingerit.gingerit import GingerIt\n",
    "\n",
    "parser = GingerIt()\n",
    "incorrect_text = \"Ths is a smple txt with som speling erors.\"\n",
    "result = parser.parse(incorrect_text)\n",
    "print(result['result'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f4fac2",
   "metadata": {},
   "source": [
    "### 5. SymSpell (symspellpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4a6dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from symspellpy import SymSpell, Verbosity\n",
    "import pkg_resources\n",
    "\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "dictionary_path = pkg_resources.resource_filename(\n",
    "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "\n",
    "incorrect_text = \"Ths is a smple txt with som speling erors.\"\n",
    "words = incorrect_text.split()\n",
    "corrected_words = [sym_spell.lookup(word, Verbosity.CLOSEST, max_edit_distance=2)[0].term for word in words]\n",
    "corrected_text = \" \".join(corrected_words)\n",
    "print(corrected_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bfaaab",
   "metadata": {},
   "source": [
    "### 6. JamSpell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b8a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jamspell\n",
    "\n",
    "corrector = jamspell.TSpellCorrector()\n",
    "corrector.LoadLangModel(\"en.bin\")  # pre-trained model file\n",
    "\n",
    "incorrect_text = \"Ths is a smple txt with som speling erors.\"\n",
    "corrected_text = corrector.FixFragment(incorrect_text)\n",
    "print(corrected_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255fc220",
   "metadata": {},
   "source": [
    "### 7. Norvig’s Spell Corrector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ff1cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple implementation using Peter Norvig's approach\n",
    "import re, collections\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "WORDS = collections.Counter(words(open('big.txt').read()))  # big corpus file\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    return known([word]) or known(edits1(word)) or [word]\n",
    "\n",
    "def known(words): \n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "incorrect_text = \"Ths is a smple txt with som speling erors.\"\n",
    "corrected_text = \" \".join([correction(word) for word in incorrect_text.split()])\n",
    "print(corrected_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ab5b4",
   "metadata": {},
   "source": [
    "### 8. Hunspell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95ed125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hunspell import HunSpell\n",
    "\n",
    "hobj = HunSpell('/usr/share/hunspell/en_US.dic', '/usr/share/hunspell/en_US.aff')\n",
    "incorrect_text = \"Ths is a smple txt with som speling erors.\"\n",
    "corrected_words = [hobj.suggest(word)[0] if hobj.suggest(word) else word for word in incorrect_text.split()]\n",
    "corrected_text = \" \".join(corrected_words)\n",
    "print(corrected_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c92ea11",
   "metadata": {},
   "source": [
    "### 9. LanguageTool (language_tool_python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e731f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import language_tool_python\n",
    "\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "incorrect_text = \"Ths is a smple txt with som speling erors.\"\n",
    "matches = tool.check(incorrect_text)\n",
    "corrected_text = language_tool_python.utils.correct(incorrect_text, matches)\n",
    "print(corrected_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17006cf9",
   "metadata": {},
   "source": [
    "### 10. Transformer/BERT-based correction (HuggingFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed52de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"prithivida/grammar_error_correcter_v1\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"prithivida/grammar_error_correcter_v1\")\n",
    "\n",
    "incorrect_text = \"Ths is a smple txt with som speling erors.\"\n",
    "inputs = tokenizer.encode(\"gec: \" + incorrect_text, return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs, max_length=128)\n",
    "corrected_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(corrected_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be392b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "text = \"Ths is a smple txt with som speling erors.\"\n",
    "\n",
    "# Tokenize first using NLTK\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Correct each word\n",
    "corrected_words = [spell.correction(word) for word in words]\n",
    "corrected_text = \" \".join(corrected_words)\n",
    "print(corrected_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e756a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d66e274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
